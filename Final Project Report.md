# **Отчёт по сравнительному анализу моделей для вопросно-ответного поиска на русском языке**

## **Введение**

В данном проекте проводится сравнительный анализ трёх моделей для задачи вопросно-ответного поиска на русском языке:

1. **T5 (cointegrated/rut5-base-multitask)** - генеративная модель
2. **GPT2 (sberbank-ai/rugpt3small_based_on_gpt2)** - генеративная модель
3. **QA (Den4ikAI/rubert_large_squad_2)** - специализированная модель для вопросно-ответных задач

Цель исследования - определить оптимальные параметры для каждой модели и сравнить их эффективность на датасете SberQuAD.

## **Методика**

### **Метрики оценки**

1. **Точное совпадение (Exact Match, EM)**: Показывает долю ответов, полностью совпадающих с эталоном
2. **F1 Score**: Гармоническое среднее между точностью и полнотой на уровне слов
3. **BLEU Score**: Метрика качества перевода, адаптированная для оценки генерации текста
4. **Время генерации**: Среднее время генерации одного ответа
5. **Длина ответа**: Среднее количество слов в ответе

### **Эксперименты**

1. **Влияние температуры генерации**: Тестирование при T=[0.1, 0.5, 1.0, 1.5, 2.0]
2. **Анализ типичных ошибок**: Качественный анализ ошибок для каждой модели

## **Результаты**

### **Сравнение моделей по температуре**

#### **T5 (cointegrated/rut5-base-multitask)**

| Температура | EM    | F1     | BLEU   | Время (с) | Длина (слов) |
|-------------|-------|--------|--------|-----------|--------------|
| 0.1         | 0.3800| 0.7355 | 0.3892 | 1.68      | 4.26         |
| 0.5         | 0.3400| 0.7096 | 0.3569 | 1.81      | 4.18         |
| **1.0**     | **0.4200**| **0.7380**| **0.3947**| 1.66      | 4.22         |
| 1.5         | 0.1800| 0.5140 | 0.2026 | 1.76      | 4.96         |
| 2.0         | 0.0000| 0.2466 | 0.0774 | 1.97      | 6.58         |

**Выводы**:
- Оптимальная температура: T=1.0
- При T=0.5 наблюдается хорошее сочетание точности и разнообразия
- Высокая температура (T=1.5, T=2.0) увеличивает длину ответа, но снижает качество

#### **GPT2 (sberbank-ai/rugpt3small_based_on_gpt2)**

| Температура | EM    | F1     | BLEU   | Время (с) | Длина (слов) |
|-------------|-------|--------|--------|-----------|--------------|
| 0.1         | 0.0000| 0.0770 | 0.0097 | 5.05      | 9.76         |
| 0.5         | 0.0000| 0.0662 | 0.0076 | 5.02      | 9.76         |
| 1.0         | 0.0000| 0.0770 | 0.0097 | 4.84      | 9.76         |
| 1.5         | 0.0000| 0.0608 | 0.0075 | 4.99      | 9.80         |
| 2.0         | 0.0000| 0.0258 | 0.0033 | 4.99      | 9.84         |

**Выводы**:
- Модель GPT2 показала низкое качество ответов при всех температурах
- Температура незначительно влияет на качество, но ответы всегда длинные (~10 слов)
- Время генерации значительно выше, чем у других моделей

#### **QA (Den4ikAI/rubert_large_squad_2)**

| Метрика            | Значение  |
|---------------------|-----------|
| EM                  | 0.5600    |
| F1 Score            | 0.7883    |
| BLEU Score          | 0.4134    |
| Время генерации (с) | 0.48      |
| Длина ответа (слов) | 3.52      |

**Выводы**:
- Модель QA показала наилучшие результаты среди всех моделей
- Самое быстрое время генерации
- Ответы короче и точнее

### **Анализ типичных ошибок**

#### **T5 (cointegrated/rut5-base-multitask)**

1. **Вопрос**: Как называется воздушное судно, выполняющее полет без пилота на борту?
   - **Ответ**: Беспилотное воздушное судно
   - **Эталон**: Беспилотное
   - **Ошибка**: Избыточная детализация

2. **Вопрос**: Синтезом каких культур являлась богемская культура?
   - **Ответ**: немецкой, чешской и еврейской культур
   - **Эталон**: Немецкой, чешской и еврейской культур
   - **Ошибка**: Регистр букв

3. **Вопрос**: Как меняется кожа у змей?
   - **Ответ**: шелушением или линькой.
   - **Эталон**: У змей кожа меняется одномоментно.
   - **Ошибка**: Неполный ответ

#### **GPT2 (sberbank-ai/rugpt3small_based_on_gpt2)**

1. **Вопрос**: Как называется воздушное судно, выполняющее полет без пилота на борту?
   - **Ответ**: Аэрокосмический термин «беспилотный летательный аппарат»
   - **Эталон**: Беспилотное
   - **Ошибка**: Полностью неверный ответ

2. **Вопрос**: Синтезом каких культур являлась богемская культура?
   - **Ответ**: то была одна из самых древних культур в мире. Какие
   - **Эталон**: Немецкой, чешской и еврейской культур
   - **Ошибка**: Полная бессмыслица

3. **Вопрос**: Как меняется кожа у змей?
   - **Ответ**: Кожа на змеином теле меняется в зависимости от того, в каком состоянии
   - **Эталон**: У змей кожа меняется одномоментно.
   - **Ошибка**: Неполный и неверный ответ

#### **QA (Den4ikAI/rubert_large_squad_2)**

1. **Вопрос**: Синтезом каких культур являлась богемская культура?
   - **Ответ**: немецкой, чешской и еврейской культур
   - **Эталон**: Немецкой, чешской и еврейской культур
   - **Ошибка**: Регистр букв

2. **Вопрос**: Как меняется кожа у змей?
   - **Ответ**: одномоментно и одним слоем
   - **Эталон**: У змей кожа меняется одномоментно.
   - **Ошибка**: Избыточная информация

3. **Вопрос**: В каком году Бунин перешел к другому издателю?
   - **Ответ**: В 1902 году
   - **Эталон**: 1902
   - **Ошибка**: Избыточная детализация

## **Выводы и рекомендации**

1. **Лучшая модель**: QA (Den4ikAI/rubert_large_squad_2) показала наилучшие результаты по всем метрикам:
   - Высокий F1 Score (0.7883)
   - Быстрое время генерации (0.48с)
   - Краткие и точные ответы

2. **Для генеративных задач**:
   - Модель T5 показывает лучшие результаты среди генеративных моделей
   - Оптимальная температура: T=1.0
   - Ответы более точные и краткие по сравнению с GPT2

3. **Модель GPT2**:
   - Показала наименьшую эффективность
   - Длинные и часто неверные ответы
   - Высокое время генерации
   - Не рекомендуется для использования в данной задаче

4. **Типичные ошибки**:
   - Избыточная детализация (все модели)
   - Неполные ответы (T5, QA)
   - Полностью неверные ответы (GPT2)
   - Проблемы с регистром (все модели)

## **Заключение**

Для задачи вопросно-ответного поиска на русском языке рекомендуется использовать специализированную модель QA (Den4ikAI/rubert_large_squad_2), которая показала наилучшие результаты по всем метрикам. Среди генеративных моделей предпочтительнее T5 с температурой 1.0, которая демонстрирует хороший баланс между точностью и разнообразием ответов. Модель GPT2 показала наименьшую эффективность и не рекомендуется для использования в данной задаче.